import streamlit as st
import requests
import asyncio
import aiohttp
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer

# --- Page Config ---
st.set_page_config(
    page_title="NotionAtlas",
    page_icon="üß≠",
    layout="wide"
)

# --- Title with Inline GitHub Icon ---
st.markdown(
    """
    <div style="display:flex; justify-content:center; align-items:center; gap:10px; padding: 20px 0;">
        <h1 style="margin-bottom:0;">üß≠ NotionAtlas</h1>
    </div>
    <h3 style="text-align:center; color: gray; font-weight: 400; margin-top: 0;">
        Turn your Notion workspace into an intelligent, searchable knowledge hub.
    </h3>
    """,
    unsafe_allow_html=True
)



# --- Load Secrets ---
LLAMA_API_URL = "https://api.llama.com/v1/chat/completions"
LLAMA_API_KEY = st.secrets["LLAMA_API_KEY"]
QDRANT_URL = st.secrets["QDRANT_URL"]
QDRANT_API_KEY = st.secrets["QDRANT_API_KEY"]
HF_TOKEN = st.secrets.get("HF_TOKEN", None)

COLLECTION_NAME = "notion_content"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"

# --- Initialize Clients ---
qdrant = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
embedder = SentenceTransformer(EMBEDDING_MODEL, use_auth_token=HF_TOKEN)

# --- Session State ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "conversation_context" not in st.session_state:
    st.session_state.conversation_context = ""


# --- Async Chat Function ---
async def chat_with_memory(user_input: str):
    # 1Ô∏è‚É£ Encode query
    vector = embedder.encode(user_input).tolist()
    
    # 2Ô∏è‚É£ Query Qdrant
    results = qdrant.query_points(
        collection_name=COLLECTION_NAME,
        query=vector,
        limit=5
    )

    # 3Ô∏è‚É£ Prepare semantic context
    context = "\n".join([
        hit.payload.get('chunk_text', '') for hit in results.points
    ]) or "No relevant context found."

    # 4Ô∏è‚É£ Update conversation memory
    st.session_state.conversation_context += f"\nUser: {user_input}"
    combined_context = (
        f"Conversation history:\n{st.session_state.conversation_context}\n\n"
        f"Relevant Notion context:\n{context}"
    )

    # 5Ô∏è‚É£ Call LLAMA API
    payload = {
        "model": "Llama-4-Maverick-17B-128E-Instruct-FP8",
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are NotionAtlas, an AI assistant for Notion workspace queries. "
                    "Use the context if available. If context is insufficient, "
                    "start with: 'Note: This answer is **generated by LLAMA** "
                    "& falls **outside the scope of the Notion workspace data.**'"
                )
            },
            {"role": "user", "content": combined_context}
        ],
        "max_tokens": 500,
        "temperature": 0.2
    }

    headers = {"Authorization": f"Bearer {LLAMA_API_KEY}", "Content-Type": "application/json"}

    async with aiohttp.ClientSession() as session:
        async with session.post(LLAMA_API_URL, json=payload, headers=headers) as resp:
            if resp.status == 200:
                data = await resp.json()
                answer = data["completion_message"]["content"]["text"].strip()
            else:
                answer = f"Error: {await resp.text()}"

    # 6Ô∏è‚É£ Save to chat history and memory
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    st.session_state.chat_history.append({"role": "assistant", "content": answer})
    st.session_state.conversation_context += f"\nAssistant: {answer}"

    return answer


# --- Chat Input ---
user_input = st.chat_input("Ask a question about your Notion workspace...")

if user_input:
    with st.spinner("Thinking..."):
        asyncio.run(chat_with_memory(user_input))

# --- Display Chat History ---
for msg in st.session_state.chat_history:
    if msg["role"] == "user":
        st.chat_message("user").markdown(msg["content"])
    else:
        st.chat_message("assistant").markdown(msg["content"])

# --- SIDEBAR: Branding, Tagline, GitHub, Author ---
with st.sidebar:
    st.markdown(
        """
        <div style="text-align:center; margin-bottom: 0.5em;">
            <img src="https://upload.wikimedia.org/wikipedia/commons/4/45/Notion_app_logo.png" width="58" style="margin-bottom: 0.7em;" />
            <div style="font-size: 1.55em; font-weight: 800; letter-spacing: -1px; margin-bottom:0.1em;">NotionAtlas</div>
            <div style="color: #7d7e8a; font-size: 1.05em; margin-bottom:1.2em;">
                <em>AI Semantic Search & RAG Assistant for Notion</em>
            </div>
        </div>
        <div style="text-align:center; margin-bottom: 1.4em;">
            <a href="https://github.com/Yashraj-Muthyapwar/NotionAtlas-AI-Semantic-Search-And-RAG-Assistant-for-Notion" target="_blank" style="text-decoration:none;">
                <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" width="28" style="vertical-align:middle; margin-right: 6px;" />
                <span style="font-size:1.10em; font-weight:500; color: #333; position:relative; top:0px;">View on GitHub</span>
            </a>
        </div>
        <hr style="border:none; border-top:1.5px solid #ececec; margin: 0.5em 0 1.2em 0;">
        <div style="color:#8a8a9c; font-size:1em; text-align:center;">
            Built by <a href="https://github.com/Yashraj-Muthyapwar" target="_blank" style="color:#0077ff; font-weight:600; text-decoration:none;">Yashraj Muthyapwar</a>
        </div>
        """,
        unsafe_allow_html=True
    )
