import streamlit as st
import requests
import asyncio
import aiohttp
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer

# --- Page Config ---
st.set_page_config(
    page_title="NotionAtlas â€“ AI Semantic Search for Notion",
    page_icon="ðŸ§­",
    layout="wide"
)

# --- Minimal Professional Styling ---
st.markdown(
    """
    <style>
    /* Clean background */
    .stApp {
        background-color: #f8f9fb;
    }
    /* Landing container */
    .landing-container {
        text-align: center;
        padding: 40px 0 30px 0;
    }
    .landing-title {
        font-size: 3em;
        font-weight: 700;
        color: #222;
        margin-bottom: 0;
    }
    .landing-subtitle {
        color: #555;
        font-weight: 400;
        margin-top: 8px;
        font-size: 1.3em;
    }
    .landing-description {
        color: #666;
        font-size: 1.05em;
        max-width: 620px;
        margin: 20px auto;
    }
    .example-queries {
        background: white;
        border-radius: 12px;
        padding: 15px 25px;
        margin: 0 auto 30px auto;
        max-width: 500px;
        box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        font-size: 0.95em;
        color: #333;
    }
    /* Chat bubbles */
    .user-msg {
        background-color: #dce6ff;
        padding: 10px 15px;
        border-radius: 15px;
        margin: 5px 0;
        max-width: 80%;
    }
    .assistant-msg {
        background-color: white;
        padding: 10px 15px;
        border-radius: 15px;
        margin: 5px 0 15px 0;
        max-width: 80%;
        box-shadow: 0 1px 4px rgba(0,0,0,0.05);
    }
    </style>
    """,
    unsafe_allow_html=True
)

# --- Landing Section ---
st.markdown(
    """
    <div class="landing-container">
        <h1 class="landing-title">ðŸ§­ NotionAtlas</h1>
        <h3 class="landing-subtitle">
            AI-Powered Semantic Search for Your Notion Workspace
        </h3>
        <p class="landing-description">
            Ask natural questions and instantly discover insights from your notes.
            NotionAtlas combines semantic search with conversational memory
            to turn your workspace into a smart knowledge hub.
        </p>
    </div>
    """,
    unsafe_allow_html=True
)

# --- Example Queries ---
st.markdown(
    """
    <div class="example-queries">
        ðŸ’¡ <b>Try asking:</b><br>
        â€¢ "Summarize my MongoDB exam prep notes"<br>
        â€¢ "What did I learn in Week 3: Sequence Models?"<br>
        â€¢ "Show me all tasks marked as 'Not Started'"
    </div>
    """,
    unsafe_allow_html=True
)

st.write("---")

st.subheader("ðŸ’¬ Ask NotionAtlas")
st.caption("Type your question below to start a conversation with your Notion workspace.")

# --- Load Secrets ---
LLAMA_API_URL = "https://api.llama.com/v1/chat/completions"
LLAMA_API_KEY = st.secrets["LLAMA_API_KEY"]
QDRANT_URL = st.secrets["QDRANT_URL"]
QDRANT_API_KEY = st.secrets["QDRANT_API_KEY"]
HF_TOKEN = st.secrets.get("HF_TOKEN", None)

COLLECTION_NAME = "notion_content"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"

# --- Initialize Clients ---
qdrant = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
embedder = SentenceTransformer(EMBEDDING_MODEL, use_auth_token=HF_TOKEN)

# --- Session State ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "conversation_context" not in st.session_state:
    st.session_state.conversation_context = ""


# --- Async Chat Function ---
async def chat_with_memory(user_input: str):
    vector = embedder.encode(user_input).tolist()
    results = qdrant.query_points(
        collection_name=COLLECTION_NAME,
        query=vector,
        limit=5
    )

    context = "\n".join([
        hit.payload.get('chunk_text', '') for hit in results.points
    ]) or "No relevant context found."

    st.session_state.conversation_context += f"\nUser: {user_input}"
    combined_context = (
        f"Conversation history:\n{st.session_state.conversation_context}\n\n"
        f"Relevant Notion context:\n{context}"
    )

    payload = {
        "model": "Llama-4-Maverick-17B-128E-Instruct-FP8",
        "messages": [
            {
                "role": "system",
                "content": (
                    "You are NotionAtlas, an AI assistant for Notion workspace queries. "
                    "Use the context if available. If context is insufficient, "
                    "start with: 'Note: This answer is **generated by LLAMA** "
                    "& falls **outside the scope of the Notion workspace data.**'"
                )
            },
            {"role": "user", "content": combined_context}
        ],
        "max_tokens": 500,
        "temperature": 0.2
    }

    headers = {"Authorization": f"Bearer {LLAMA_API_KEY}", "Content-Type": "application/json"}

    async with aiohttp.ClientSession() as session:
        async with session.post(LLAMA_API_URL, json=payload, headers=headers) as resp:
            if resp.status == 200:
                data = await resp.json()
                answer = data["completion_message"]["content"]["text"].strip()
            else:
                answer = f"Error: {await resp.text()}"

    st.session_state.chat_history.append({"role": "user", "content": user_input})
    st.session_state.chat_history.append({"role": "assistant", "content": answer})
    st.session_state.conversation_context += f"\nAssistant: {answer}"

    return answer


# --- Chat Input ---
user_input = st.chat_input("Ask a question about your Notion workspace...")

if user_input:
    with st.spinner("Thinking..."):
        asyncio.run(chat_with_memory(user_input))

# --- Display Chat History as Styled Bubbles ---
for msg in st.session_state.chat_history:
    if msg["role"] == "user":
        st.markdown(f"<div class='user-msg'>{msg['content']}</div>", unsafe_allow_html=True)
    else:
        st.markdown(f"<div class='assistant-msg'>{msg['content']}</div>", unsafe_allow_html=True)
